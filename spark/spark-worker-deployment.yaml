apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: spark-worker
  name: spark-worker
spec:
  serviceName: spark-worker
  replicas: 3
  selector:
    matchLabels:
      app: spark-worker
  template:
    metadata:
      labels:
        app: spark-worker
    spec:
      serviceAccountName: ignite
      containers:
      - env:
        - name: CORE_CONF_fs_defaultFS
          valueFrom:
            configMapKeyRef:
              key: CORE_CONF_fs_defaultFS
              name: spark-worker-hadoop-env
        - name: CORE_CONF_hadoop_http_staticuser_user
          valueFrom:
            configMapKeyRef:
              key: CORE_CONF_hadoop_http_staticuser_user
              name: spark-worker-hadoop-env
        - name: CORE_CONF_hadoop_proxyuser_hue_groups
          valueFrom:
            configMapKeyRef:
              key: CORE_CONF_hadoop_proxyuser_hue_groups
              name: spark-worker-hadoop-env
        - name: CORE_CONF_hadoop_proxyuser_hue_hosts
          valueFrom:
            configMapKeyRef:
              key: CORE_CONF_hadoop_proxyuser_hue_hosts
              name: spark-worker-hadoop-env
        - name: CORE_CONF_io_compression_codecs
          valueFrom:
            configMapKeyRef:
              key: CORE_CONF_io_compression_codecs
              name: spark-worker-hadoop-env
        - name: HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check
          valueFrom:
            configMapKeyRef:
              key: HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check
              name: spark-worker-hadoop-env
        - name: HDFS_CONF_dfs_permissions_enabled
          valueFrom:
            configMapKeyRef:
              key: HDFS_CONF_dfs_permissions_enabled
              name: spark-worker-hadoop-env
        - name: HDFS_CONF_dfs_webhdfs_enabled
          valueFrom:
            configMapKeyRef:
              key: HDFS_CONF_dfs_webhdfs_enabled
              name: spark-worker-hadoop-env
        - name: MAPRED_CONF_mapred_child_java_opts
          valueFrom:
            configMapKeyRef:
              key: MAPRED_CONF_mapred_child_java_opts
              name: spark-worker-hadoop-env
        - name: MAPRED_CONF_mapreduce_framework_name
          valueFrom:
            configMapKeyRef:
              key: MAPRED_CONF_mapreduce_framework_name
              name: spark-worker-hadoop-env
        - name: MAPRED_CONF_mapreduce_map_java_opts
          valueFrom:
            configMapKeyRef:
              key: MAPRED_CONF_mapreduce_map_java_opts
              name: spark-worker-hadoop-env
        - name: MAPRED_CONF_mapreduce_map_memory_mb
          valueFrom:
            configMapKeyRef:
              key: MAPRED_CONF_mapreduce_map_memory_mb
              name: spark-worker-hadoop-env
        - name: MAPRED_CONF_mapreduce_reduce_java_opts
          valueFrom:
            configMapKeyRef:
              key: MAPRED_CONF_mapreduce_reduce_java_opts
              name: spark-worker-hadoop-env
        - name: MAPRED_CONF_mapreduce_reduce_memory_mb
          valueFrom:
            configMapKeyRef:
              key: MAPRED_CONF_mapreduce_reduce_memory_mb
              name: spark-worker-hadoop-env
        - name: SPARK_MASTER
          value: spark://spark-master-0.spark.default.svc.cluster.local:7077
        - name: SPARK_WORKER_OPTS
          valueFrom:
            configMapKeyRef:
              key: SPARK_WORKER_OPTS
              name: spark-worker-hadoop-env
        - name: YARN_CONF_mapred_map_output_compress_codec
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_mapred_map_output_compress_codec
              name: spark-worker-hadoop-env
        - name: YARN_CONF_mapreduce_map_output_compress
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_mapreduce_map_output_compress
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_log___aggregation___enable
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_log___aggregation___enable
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_log_server_url
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_log_server_url
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_nodemanager_aux___services
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_nodemanager_aux___services
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_nodemanager_disk___health___checker_max___disk___utilization___per___disk___percentage
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_nodemanager_disk___health___checker_max___disk___utilization___per___disk___percentage
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_nodemanager_remote___app___log___dir
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_nodemanager_remote___app___log___dir
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_nodemanager_resource_cpu___vcores
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_nodemanager_resource_cpu___vcores
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_nodemanager_resource_memory___mb
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_nodemanager_resource_memory___mb
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_resourcemanager_address
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_resourcemanager_address
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_resourcemanager_fs_state___store_uri
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_resourcemanager_fs_state___store_uri
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_resourcemanager_hostname
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_resourcemanager_hostname
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_resourcemanager_recovery_enabled
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_resourcemanager_recovery_enabled
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_resourcemanager_resource__tracker_address
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_resourcemanager_resource__tracker_address
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_resourcemanager_scheduler_address
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_resourcemanager_scheduler_address
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_resourcemanager_scheduler_class
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_resourcemanager_scheduler_class
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_resourcemanager_store_class
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_resourcemanager_store_class
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___mb
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___mb
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___vcores
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___vcores
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_timeline___service_enabled
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_timeline___service_enabled
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_timeline___service_generic___application___history_enabled
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_timeline___service_generic___application___history_enabled
              name: spark-worker-hadoop-env
        - name: YARN_CONF_yarn_timeline___service_hostname
          valueFrom:
            configMapKeyRef:
              key: YARN_CONF_yarn_timeline___service_hostname
              name: spark-worker-hadoop-env
        image: bde2020/spark-worker:2.2.0-hadoop2.8-hive-java8
        name: spark-worker
        ports:
        - containerPort: 8081
        resources: {}
        volumeMounts:
        - mountPath: /spark/work
          name: spark-data
      nodeSelector:
        worker: "true"
      restartPolicy: Always
  volumeClaimTemplates:
  - metadata:
      name: spark-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: spark
      resources:
        requests:
          storage: 99Gi
